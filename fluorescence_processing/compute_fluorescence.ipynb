{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take in raw fluorescence images and compute a scalar fluorescence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from pathlib import Path\n",
    "from bsccm import BSCCM \n",
    "\n",
    "\n",
    "home = str(Path.home())\n",
    "data_root = home + '/BSCCM_local/BSCCM/'\n",
    "\n",
    "dataset = BSCCM(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383342          \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405569          \r"
     ]
    }
   ],
   "source": [
    "fluor_dataframe = pd.DataFrame()\n",
    "# copy over global insex\n",
    "fluor_dataframe.insert(0, 'global_index', dataset.index_dataframe.global_index.to_list())\n",
    "\n",
    "for index in dataset.index_dataframe.global_index:\n",
    "    index = int(index)\n",
    "    print('{}          \\r'.format(index), end='')\n",
    "\n",
    "    for ch_index, fluor_channel in enumerate(dataset.global_metadata['fluorescence']['channel_names']):\n",
    "        #### get shading correction ####\n",
    "#         background = dataset.get_unstained_background(index, fluor_channel).astype(np.float32)\n",
    "#         foreground = dataset.get_background(index, contrast_type='fluor', \n",
    "#                                             channel=fluor_channel, percentile=50).astype(np.float32)\n",
    "#         shading = foreground - background\n",
    "#         # smooth\n",
    "#         shading = ndi.gaussian_filter(shading, 2.5)\n",
    "        \n",
    "#         if np.any(shading <= 0):\n",
    "#             num = np.sum(shading <= 0)\n",
    "#             if num > 50:\n",
    "#                 print('{} nonpositive shading pix detected at index {}   ch_index {}'.format(num, index, ch_index))\n",
    "#             #hot pixels seem to creat occasional 0 or subzero patches\n",
    "#             shading[shading <= 0] = np.min(shading[shading > 0])\n",
    "     \n",
    "#         # normalize shaing correction so that it doesn't attenuate absolute fluorescence value\n",
    "#         shading = shading / np.linalg.norm(shading)\n",
    "    \n",
    "        #compute fluorescence\n",
    "        image = dataset.read_image(index, contrast_type='fluor', channel=fluor_channel).astype(np.float32)\n",
    "#         background_subtracted = image.astype(np.float32) - background\n",
    "#         corrected = background_subtracted / shading\n",
    "\n",
    "        yy, xx = np.meshgrid(np.arange(image.shape[0]), np.arange(image.shape[0]))\n",
    "        fluor_mask = np.sqrt((yy - image.shape[0]/2) ** 2 + (xx - image.shape[1]/2) ** 2) < image.shape[0]/2\n",
    "        fluor_mask_pixels = image[fluor_mask]\n",
    "        fluor_background_pixels = image[np.logical_not(fluor_mask)]\n",
    "        \n",
    "        # clip at zero here before summing so you dont get everything at exactly equal to 0\n",
    "#         fluor_mask_pixels[fluor_mask_pixels < 0] = 0\n",
    "        total_fluor = np.sum(fluor_mask_pixels)\n",
    "        fluor_dataframe.loc[index, fluor_channel + '_total_raw'] = total_fluor\n",
    "        total_background = np.sum(fluor_background_pixels)\n",
    "        fluor_dataframe.loc[index, fluor_channel + '_background'] = total_background\n",
    "    \n",
    "        #same thing but with local background subtraction\n",
    "#         local_background = np.percentile(fluor_mask_pixels, 5)\n",
    "#         total_fluor_local_background_subtraction = np.sum(fluor_mask_pixels - local_background)\n",
    "#         fluor_dataframe.loc[index, fluor_channel + '_total_local_background_subtracted'] = total_fluor\n",
    "    \n",
    "        \n",
    "    \n",
    "#         local_background = np.percentile(fluor_mask_pixels, 5, axis=1)\n",
    "#         mean_fluor = np.sum(fluor_mask_pixels - local_background[:, None], axis=1)\n",
    "#         mean_fluor_without_local_subtraction = np.sum(fluor_mask_pixels, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluor_dataframe.to_csv(data_root + 'BSCCM_surface_markers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with how to get rid of values less than 0 in computed shading...seems like gaussian filtering the image supresses these noisy values and solves problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "background_crop = crop(background, (y, x))\n",
    "        if shading is not None:\n",
    "            shading_crop = crop(shading, (y, x))\n",
    "        else:\n",
    "            shading_crop = np.ones_like(background_crop)\n",
    "        fluor_crop = crops_dataset['{}/{}'.format(dataset_index, crop_name)].get_orthogonal_selection(\n",
    "            (fluor_channel_indices, slice(None), slice(None)))\n",
    "        fluor_crop_corrected = (fluor_crop - background_crop) / shading_crop\n",
    "        # mask only pixels within 130 pixel diameter circle\n",
    "        yy, xx = np.meshgrid(np.arange(150), np.arange(150))\n",
    "        fluor_mask = np.sqrt((yy - 75) ** 2 + (xx - 75) ** 2) < 65\n",
    "        fluor_mask_pixels = fluor_crop_corrected[:, fluor_mask]\n",
    "        local_background = np.percentile(fluor_mask_pixels, 5, axis=1)\n",
    "        mean_fluor = np.sum(fluor_mask_pixels - local_background[:, None], axis=1)\n",
    "        mean_fluor_without_local_subtraction = np.sum(fluor_mask_pixels, axis=1)\n",
    "\n",
    "        # napari_show({'b': background_crop, 's': shading_crop, 'f': fluor_crop, 'f-b': fluor_crop - background_crop,\n",
    "        #              'corrected': fluor_crop_corrected})\n",
    "\n",
    "        mean_fluor[mean_fluor < 0] = 0\n",
    "        mean_fluor_without_local_subtraction[mean_fluor_without_local_subtraction < 0]\n",
    "        mean_fluors.append(mean_fluor)\n",
    "        mean_fluors_without_background_sub.append(mean_fluor_without_local_subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Which dataset indices correspond to which flatfield\n",
    "# TODO Replace this with something read from the dataframe\n",
    "# TODO Need to account for dataset 13 being off...\n",
    "\n",
    "fluor_channel_indices = np.array([crops_dataset[str(datasets_920[0])]['all_blobs'].attrs['channel_names'].index(n) for n in\n",
    "                   ['F1_BV711', 'F2_BV650', 'F3_BV605', 'F4_BV570', 'F5_BV510', 'F6_BV421']])\n",
    "\n",
    "fluor_names = ['BV711', 'BV650', 'BV605', 'BV570', 'BV510', 'BV421']\n",
    "new_cols = {name: np.zeros((dataframe.size, )) for name in fluor_names + [n + '_without_local_background_sub' for n in fluor_names]}\n",
    "#add new columns to dataframe\n",
    "dataframe = dataframe.join(pd.DataFrame(new_cols))\n",
    "\n",
    "\n",
    "def compute_fluoresence(dataframe, dataset_index, background, shading=None):\n",
    "    \"\"\"\n",
    "    Do background substraction and optionally, shading\n",
    "    \"\"\"\n",
    "    print('dataset {}'.format(dataset_index))\n",
    "    in_dataset_indices = np.flatnonzero(dataframe['dataset_index'] == dataset_index)\n",
    "    dataset_dataframe = dataframe.loc[in_dataset_indices]\n",
    "    y_coords = dataset_dataframe['blob_y'].to_numpy()\n",
    "    x_coords = dataset_dataframe['blob_x'].to_numpy()\n",
    "    crop_names = dataset_dataframe['blob_name'].to_list()\n",
    "\n",
    "    mean_fluors_without_background_sub = []\n",
    "    mean_fluors = []\n",
    "    for i, (y, x, crop_name) in enumerate(zip(y_coords, x_coords, crop_names)):\n",
    "        print('{} of {}\\r'.format(i, y_coords.size), end='')\n",
    "        background_crop = crop(background, (y, x))\n",
    "        if shading is not None:\n",
    "            shading_crop = crop(shading, (y, x))\n",
    "        else:\n",
    "            shading_crop = np.ones_like(background_crop)\n",
    "        fluor_crop = crops_dataset['{}/{}'.format(dataset_index, crop_name)].get_orthogonal_selection(\n",
    "            (fluor_channel_indices, slice(None), slice(None)))\n",
    "        fluor_crop_corrected = (fluor_crop - background_crop) / shading_crop\n",
    "        # mask only pixels within 130 pixel diameter circle\n",
    "        yy, xx = np.meshgrid(np.arange(150), np.arange(150))\n",
    "        fluor_mask = np.sqrt((yy - 75) ** 2 + (xx - 75) ** 2) < 65\n",
    "        fluor_mask_pixels = fluor_crop_corrected[:, fluor_mask]\n",
    "        local_background = np.percentile(fluor_mask_pixels, 5, axis=1)\n",
    "        mean_fluor = np.sum(fluor_mask_pixels - local_background[:, None], axis=1)\n",
    "        mean_fluor_without_local_subtraction = np.sum(fluor_mask_pixels, axis=1)\n",
    "\n",
    "        # napari_show({'b': background_crop, 's': shading_crop, 'f': fluor_crop, 'f-b': fluor_crop - background_crop,\n",
    "        #              'corrected': fluor_crop_corrected})\n",
    "\n",
    "        mean_fluor[mean_fluor < 0] = 0\n",
    "        mean_fluor_without_local_subtraction[mean_fluor_without_local_subtraction < 0]\n",
    "        mean_fluors.append(mean_fluor)\n",
    "        mean_fluors_without_background_sub.append(mean_fluor_without_local_subtraction)\n",
    "\n",
    "    without_local_sub = np.stack(mean_fluors_without_background_sub)\n",
    "    mean_fluors = np.stack(mean_fluors)\n",
    "    return mean_fluors, without_local_sub\n",
    "\n",
    "def correct_and_compute_fluorescence(ids, do_local_backgrounds=True, shading=True):\n",
    "    # Compute shading corrections from loess of all stain data\n",
    "    mean_fluorescences = {}\n",
    "    without_background_subtraction = {}\n",
    "    for dataset in ids:\n",
    "        if dataset in datasets_813:\n",
    "            background = shading_file['813_backgrounds']\n",
    "            ff = shading_file['813_ff_slide']\n",
    "        elif dataset in datasets_828:\n",
    "            background = shading_file['828_backgrounds']\n",
    "            ff = shading_file['828_ff_slide']\n",
    "        elif dataset in datasets_920:\n",
    "            background = shading_file['920_backgrounds']\n",
    "            ff = shading_file['920_ff_slide']\n",
    "        shading_corr = ff - 0.92 * background\n",
    "\n",
    "        #normalize by median brightness\n",
    "        shading_corr = shading_corr / np.mean(shading_corr, axis=(1,2))[:,None,None]\n",
    "\n",
    "        mean_fluorescence, fluor_without_local_background = compute_fluoresence(dataframe, dataset, background,\n",
    "                                    shading=shading_corr if shading else None)\n",
    "        mean_fluorescences[dataset] = mean_fluorescence\n",
    "        without_background_subtraction[dataset] = fluor_without_local_background\n",
    "    return mean_fluorescences, without_background_subtraction\n",
    "\n",
    "\n",
    "ids = np.unique(dataframe['dataset_index'].to_numpy().astype(np.int))\n",
    "\n",
    "mean_fluorescences, mean_fluorescences_no_bckd_sub = correct_and_compute_fluorescence(ids, do_local_backgrounds=True, shading=True)\n",
    "for dataset_index in ids:\n",
    "    in_dataset_indices = np.flatnonzero(dataframe['dataset_index'] == dataset_index)\n",
    "    new_data = np.concatenate([mean_fluorescences[dataset_index],\n",
    "                               mean_fluorescences_no_bckd_sub[dataset_index]], axis=1)\n",
    "    for i, col_name in enumerate(new_cols.keys()):\n",
    "        dataframe.loc[in_dataset_indices, col_name] = new_data[:, i]\n",
    "\n",
    "\n",
    "dataframe.to_csv(data_root + 'crops_filtered_record_single_with_fluor_normalized_ff.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
